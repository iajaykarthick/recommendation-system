{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import load_config\n",
    "config = load_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movielens-20m-dataset.zip to data\r\n",
      " 99%|███████████████████████████████████████▍| 193M/195M [00:06<00:00, 54.0MB/s]\r\n",
      "100%|████████████████████████████████████████| 195M/195M [00:06<00:00, 32.3MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p data\n",
    "# !kaggle datasets download -d grouplens/movielens-20m-dataset -p data/ --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ajaykarthicksenthilkumar/dev/personal/recommendation-system/data/ml-32m\n",
      "Files already exist. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_and_unzip(zip_url, output_dir):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    raw_dir = config['data_paths']['raw']\n",
    "    print(raw_dir)\n",
    "    if (\n",
    "        os.path.exists(raw_dir) and \n",
    "        all([file in os.listdir(raw_dir) for file in ['links.csv', 'movies.csv', 'ratings.csv', 'tags.csv']])\n",
    "    ):\n",
    "        print(\"Files already exist. Skipping download.\")\n",
    "        return\n",
    "    \n",
    "    # Download the zip file\n",
    "    response = requests.get(zip_url)\n",
    "    zip_path = os.path.join(output_dir, os.path.basename(zip_url))\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    \n",
    "    # Remove the zip file\n",
    "    os.remove(zip_path)\n",
    "        \n",
    "zip_url = \"https://files.grouplens.org/datasets/movielens/ml-32m.zip\"\n",
    "download_and_unzip(zip_url, \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/17 21:34:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "\n",
    "# spark.driver.memory is used to set the memory for the spark driver process. \n",
    "spark = SparkSession.builder.master(\"local[4]\") \\\n",
    "                    .appName('recommendation_system') \\\n",
    "                    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "                    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(config['data_paths']['raw'], 'ratings.csv')\n",
    "\n",
    "\n",
    "df = spark.read.options(\n",
    "            header=True,\n",
    "            inferSchema=True\n",
    "        ) \\\n",
    "        .csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:==========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 32000204 ratings in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"There are totally {df.count()} ratings in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|     17|   4.0|944249077|\n",
      "|     1|     25|   1.0|944250228|\n",
      "|     1|     29|   2.0|943230976|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of users is 200948\n",
      "User ID starts from 1\n",
      "User ID ends at 200948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"The unique number of users is {df.select(countDistinct('userId')).collect()[0][0]}\\n\"\n",
    "      f\"User ID starts from {df.agg({'userId': 'min'}).collect()[0][0]}\\n\"\n",
    "      f\"User ID ends at {df.agg({'userId': 'max'}).collect()[0][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of movies is 84432\n",
      "Movie ID starts from 1\n",
      "Movie ID ends at 292757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"The unique number of movies is {df.select(countDistinct('movieId')).collect()[0][0]}\\n\"\n",
    "      f\"Movie ID starts from {df.agg({'movieId': 'min'}).collect()[0][0]}\\n\"\n",
    "      f\"Movie ID ends at {df.agg({'movieId': 'max'}).collect()[0][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|userIdx|\n",
      "+------+-------+\n",
      "|     1|      0|\n",
      "|     2|      1|\n",
      "|     3|      2|\n",
      "|     4|      3|\n",
      "|     5|      4|\n",
      "|     6|      5|\n",
      "|     7|      6|\n",
      "|     8|      7|\n",
      "|     9|      8|\n",
      "|    10|      9|\n",
      "|    11|     10|\n",
      "|    12|     11|\n",
      "|    13|     12|\n",
      "|    14|     13|\n",
      "|    15|     14|\n",
      "|    16|     15|\n",
      "|    17|     16|\n",
      "|    18|     17|\n",
      "|    19|     18|\n",
      "|    20|     19|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# create unique user mappings\n",
    "unique_users = df.select('userId').distinct().sort('userId')\n",
    "unique_users = unique_users.withColumn(\"userIdx\", monotonically_increasing_id())\n",
    "unique_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|movieId|movieIdx|\n",
      "+-------+--------+\n",
      "|      1|       0|\n",
      "|      2|       1|\n",
      "|      3|       2|\n",
      "|      4|       3|\n",
      "|      5|       4|\n",
      "|      6|       5|\n",
      "|      7|       6|\n",
      "|      8|       7|\n",
      "|      9|       8|\n",
      "|     10|       9|\n",
      "|     11|      10|\n",
      "|     12|      11|\n",
      "|     13|      12|\n",
      "|     14|      13|\n",
      "|     15|      14|\n",
      "|     16|      15|\n",
      "|     17|      16|\n",
      "|     18|      17|\n",
      "|     19|      18|\n",
      "|     20|      19|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create unique movie mappings\n",
    "unique_movies = df.select('movieId').distinct().sort('movieId')\n",
    "unique_movies = unique_movies.withColumn(\"movieIdx\", monotonically_increasing_id())\n",
    "unique_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+-------+--------+\n",
      "|movieId|userId|rating| timestamp|userIdx|movieIdx|\n",
      "+-------+------+------+----------+-------+--------+\n",
      "|   1088|   148|   0.5|1471747769|    147|    1061|\n",
      "|   2366|   148|   1.0|1471747783|    147|    2275|\n",
      "|   4519|   148|   1.0|1471747756|    147|    4415|\n",
      "|   1580|   496|   3.5|1633649130|    495|    1523|\n",
      "|   1580|   833|   2.5|1193952315|    832|    1523|\n",
      "|   1645|   833|   4.0|1198795114|    832|    1583|\n",
      "|   3175|   833|   3.0|1196235442|    832|    3082|\n",
      "|   3997|   833|   2.0|1193993251|    832|    3894|\n",
      "|  44022|   833|   4.0|1193956572|    832|   10668|\n",
      "|   2366|  1088|   4.0| 992200629|   1087|    2275|\n",
      "|   3175|  1088|   3.0| 992201135|   1087|    3082|\n",
      "| 175197|  1238|   2.0|1515524615|   1237|   46161|\n",
      "|   1088|  1580|   3.5|1122328147|   1579|    1061|\n",
      "|   1959|  2122|   2.0| 975701849|   2121|    1870|\n",
      "|   6620|  2142|   4.0|1108961715|   2141|    6498|\n",
      "|   1591|  3794|   4.0|1215501092|   3793|    1534|\n",
      "|   1580|  3918|   5.0|1560146327|   3917|    1523|\n",
      "| 217119|  4101|   2.0|1590196827|   4100|   64812|\n",
      "|   1088|  4935|   5.0|1297551924|   4934|    1061|\n",
      "|   1580|  4935|   5.0|1297558296|   4934|    1523|\n",
      "+-------+------+------+----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join the mappings with the original dataframe\n",
    "df_with_mapped_ids = df.join(unique_users, on=\"userId\").join(unique_movies, on=\"movieId\")\n",
    "df_with_mapped_ids.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 162:======================>                                  (2 + 3) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of users is 200948\n",
      "User ID starts from 0\n",
      "User ID ends at 200947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"The unique number of users is {df_with_mapped_ids.select(countDistinct('userIdx')).collect()[0][0]}\\n\"\n",
    "      f\"User ID starts from {df_with_mapped_ids.agg({'userIdx': 'min'}).collect()[0][0]}\\n\"\n",
    "      f\"User ID ends at {df_with_mapped_ids.agg({'userIdx': 'max'}).collect()[0][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 230:======================>                                  (2 + 3) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of movies is 84432\n",
      "Movie ID starts from 0\n",
      "Movie ID ends at 84431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"The unique number of movies is {df_with_mapped_ids.select(countDistinct('movieIdx')).collect()[0][0]}\\n\"\n",
    "      f\"Movie ID starts from {df_with_mapped_ids.agg({'movieIdx': 'min'}).collect()[0][0]}\\n\"\n",
    "      f\"Movie ID ends at {df_with_mapped_ids.agg({'movieIdx': 'max'}).collect()[0][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(config['data_paths']['processed'], 'ratings.parquet')\n",
    "\n",
    "df_with_mapped_ids.write \\\n",
    "    .parquet(file_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
